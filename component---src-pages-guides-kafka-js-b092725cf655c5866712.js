(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{CYc0:function(e,n,r){"use strict";r.r(n);var a=r("zBv9"),t=r("q1tI"),s=r.n(t),l=r("TJpk"),i=r("rCNW"),o=r("KwlC"),u=(r("rGqo"),r("yt8O"),r("Btvt"),r("RW0V"),r("91GP"),r("w+gZ"));function c(e){var n=e.children,r=e.id,a=e.version,t=function(e,n){if(null==e)return{};var r,a,t={},s=Object.keys(e);for(a=0;a<s.length;a++)r=s[a],n.indexOf(r)>=0||(t[r]=e[r]);return t}(e,["children","id","version"]),l="https://www.nuget.org/packages/"+r;return a&&(l+="/"+a),s.a.createElement(u.a,Object.assign({},t,{to:l}),n||r)}var g="Building Kafka producers and consumers";n.default=function(){var e=a.data.site.siteMetadata,n=e.latestRelease,r=e.projectName;return s.a.createElement(s.a.Fragment,null,s.a.createElement(l.Helmet,null,s.a.createElement("title",null,g)),s.a.createElement("h1",null,g),s.a.createElement("p",null,r," ships with first-class support for ",s.a.createElement(u.a,{to:"https://github.com/confluentinc/confluent-kafka-dotnet"},"Confluent’s Kafka clients"),", the shortest path to creating Kafka producers and consumers in .NET."),s.a.createElement("h2",null,"Using Confluent’s client builders"),s.a.createElement("p",null,"First, add a reference to the Chr.Avro.Confluent package:"),s.a.createElement(i.a,{language:"bash"},"$ dotnet add package Chr.Avro.Confluent --version "+n),s.a.createElement("p",null,"Chr.Avro.Confluent depends on ",s.a.createElement(c,{id:"Confluent.Kafka"}),", which contains ",s.a.createElement(o.a,{id:"T:Confluent.Kafka.ProducerBuilder`2"},"producer")," and ",s.a.createElement(o.a,{id:"T:Confluent.Kafka.ConsumerBuilder`2"},"consumer")," builders. To build a ",s.a.createElement(u.a,{to:"https://www.confluent.io/confluent-schema-registry/"},"Schema Registry"),"-integrated producer, use the producer builder in tandem with ",r,"’s Avro extension methods:"),s.a.createElement(i.a,{language:"csharp"},'using Chr.Avro.Confluent;\nusing Confluent.Kafka;\nusing Confluent.SchemaRegistry;\nusing System;\nusing System.Threading.Tasks;\n\nnamespace Chr.Avro.Examples.KafkaProducer\n{\n    public class ExampleValue\n    {\n        public string Property { get; set; }\n    }\n\n    public class Program\n    {\n        public static async Task Main(string[] args)\n        {\n            var producerConfig = new ProducerConfig()\n            {\n                BootstrapServers = "broker1:9092,broker2:9092"\n            };\n\n            var registryConfig = new RegistryConfig()\n            {\n                SchemaRegistryUrl = "http://registry:8081"\n            };\n\n            using (var registry = new CachedSchemaRegistryClient(registryConfig))\n            {\n                var builder = new ProducerBuilder<Ignore, ExampleValue>(producerConfig)\n                    .SetAvroValueSerializer(registry, registerAutomatically: false)\n                    .SetErrorHandler((_, error) => Console.Error.WriteLine(error.ToString()));\n\n                using (var producer = builder.Build())\n                {\n                    await producer.ProduceAsync("example_topic", new Message<Ignore, ExampleValue>\n                    {\n                        Value = new ExampleValue\n                        {\n                            Property = "example!"\n                        }\n                    });\n                }\n            }\n        }\n    }\n}'),s.a.createElement("p",null,"The serializer assumes (per Confluent convention) that the value subject for ",s.a.createElement("code",null,"example_topic")," is ",s.a.createElement("code",null,"example_topic-value"),". (The key subject would be ",s.a.createElement("code",null,"example_topic-key"),".) When messages are published, the serializer will attempt to pull down a schema from the Schema Registry. The serializer can be configured to generate and register a schema automatically if one doesn’t exist."),s.a.createElement("p",null,"Building consumers works in a similar way—schemas will be retrieved from the Schema Registry as messages are consumed:"),s.a.createElement(i.a,{language:"csharp"},'using Chr.Avro.Confluent;\nusing Confluent.Kafka;\nusing Confluent.SchemaRegistry;\nusing System;\n\nnamespace Chr.Avro.Examples.KafkaConsumer\n{\n    public class ExampleValue\n    {\n        public string Property { get; set; }\n    }\n\n    public class Program\n    {\n        public static void Main(string[] args)\n        {\n            var consumerConfig = new ConsumerConfig()\n            {\n                BootstrapServers = "broker1:9092,broker2:9092",\n                GroupId = "example_consumer_group"\n            };\n\n            var registryConfig = new RegistryConfig()\n            {\n                SchemaRegistryUrl = "http://registry:8081"\n            };\n\n            using (var registry = new CachedSchemaRegistryClient(registryClient))\n            {\n                var builder = new ConsumerBuilder<Ignore, ExampleValue>(consumerConfig)\n                    .SetAvroValueDeserializer(registry)\n                    .SetErrorHandler((_, error) => Console.Error.WriteLine(error.ToString()));\n\n                using (var consumer = builder.Build())\n                {\n                    consumer.Subscribe("example_topic");\n\n                    while (true)\n                    {\n                        var result = consumer.Consume();\n                        Console.WriteLine(result.Value.Property);\n                    }\n                }\n            }\n        }\n    }\n}'))}},zBv9:function(e){e.exports=JSON.parse('{"data":{"site":{"siteMetadata":{"latestRelease":"4.1.0","projectName":"Chr.Avro"}}}}')}}]);
//# sourceMappingURL=component---src-pages-guides-kafka-js-b092725cf655c5866712.js.map